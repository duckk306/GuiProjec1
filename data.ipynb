{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665322bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from analysis.analyzer import TTTH_Analyzer\n",
    "from processor.feature import FeatureProcessor\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "# from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "from pyvi import ViTokenizer\n",
    "from underthesea import word_tokenize\n",
    "from gensim import corpora, models, similarities\n",
    "from tqdm import tqdm\n",
    "_analyzer = TTTH_Analyzer()\n",
    "_processor = FeatureProcessor()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_motobikes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd1e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tiêu đề</th>\n",
       "      <th>Giá</th>\n",
       "      <th>Khoảng giá min</th>\n",
       "      <th>Khoảng giá max</th>\n",
       "      <th>Mô tả chi tiết</th>\n",
       "      <th>Thương hiệu</th>\n",
       "      <th>Dòng xe</th>\n",
       "      <th>Năm đăng ký</th>\n",
       "      <th>Số Km đã đi</th>\n",
       "      <th>Loại xe</th>\n",
       "      <th>Dung tích xe</th>\n",
       "      <th>Xuất xứ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ban xe</td>\n",
       "      <td>2.500.000 đ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do mình dư xe không dùng nữa, xe máy móc vẫn c...</td>\n",
       "      <td>Aprilia</td>\n",
       "      <td>2015 RSV4 R APRC ABS</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>Tay ga</td>\n",
       "      <td>50 - 100 cc</td>\n",
       "      <td>Việt Nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cần bán chiếc aprillia gt rs200 xe trùm mềm</td>\n",
       "      <td>81.000.000 đ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xe nhà trùm mềm chỉ đẩy ra đẩy vô nay phụ huyn...</td>\n",
       "      <td>Aprilia</td>\n",
       "      <td>SR GT 200</td>\n",
       "      <td>2023</td>\n",
       "      <td>5000</td>\n",
       "      <td>Tay ga</td>\n",
       "      <td>100 - 175 cc</td>\n",
       "      <td>Việt Nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bán xe Sr Gt 200 ít sử dụng do đi oto</td>\n",
       "      <td>72.000.000 đ</td>\n",
       "      <td>69 tr</td>\n",
       "      <td>81 tr</td>\n",
       "      <td>Xe biển hcm, ít sử dụng còn rất mới\\nLiên hệ: ***</td>\n",
       "      <td>Aprilia</td>\n",
       "      <td>SR GT 200</td>\n",
       "      <td>2022</td>\n",
       "      <td>10000</td>\n",
       "      <td>Tay ga</td>\n",
       "      <td>100 - 175 cc</td>\n",
       "      <td>Đang cập nhật</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      Tiêu đề           Giá  \\\n",
       "0   1                                       Ban xe   2.500.000 đ   \n",
       "1   2  Cần bán chiếc aprillia gt rs200 xe trùm mềm  81.000.000 đ   \n",
       "2   3        Bán xe Sr Gt 200 ít sử dụng do đi oto  72.000.000 đ   \n",
       "\n",
       "  Khoảng giá min Khoảng giá max  \\\n",
       "0            NaN            NaN   \n",
       "1            NaN            NaN   \n",
       "2          69 tr          81 tr   \n",
       "\n",
       "                                      Mô tả chi tiết Thương hiệu  \\\n",
       "0  Do mình dư xe không dùng nữa, xe máy móc vẫn c...     Aprilia   \n",
       "1  Xe nhà trùm mềm chỉ đẩy ra đẩy vô nay phụ huyn...     Aprilia   \n",
       "2  Xe biển hcm, ít sử dụng còn rất mới\\nLiên hệ: ***     Aprilia   \n",
       "\n",
       "                Dòng xe Năm đăng ký  Số Km đã đi Loại xe  Dung tích xe  \\\n",
       "0  2015 RSV4 R APRC ABS        2008           20  Tay ga   50 - 100 cc   \n",
       "1             SR GT 200        2023         5000  Tay ga  100 - 175 cc   \n",
       "2             SR GT 200        2022        10000  Tay ga  100 - 175 cc   \n",
       "\n",
       "         Xuất xứ  \n",
       "0       Việt Nam  \n",
       "1       Việt Nam  \n",
       "2  Đang cập nhật  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['Địa chỉ','Tình trạng',\n",
    "       'Chính sách bảo hành', 'Trọng lượng', 'Href'])\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f69dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_numeric before fill missing values: 65\n",
      "cc_numeric after fill missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Sắp xếp dữ liệu theo Thương hiệu, Dòng xe, Loại xe (tăng dần)\n",
    "data = data.sort_values(by=['Thương hiệu', 'Dòng xe', 'Loại xe'], ascending=[True, True, True])\n",
    "# Reset lại index sau khi sắp xếp\n",
    "data = data.reset_index(drop=True)\n",
    "###############################\n",
    "\n",
    "#Chuẩn hóa cột \"Giá\"\n",
    "data['Giá'] = (\n",
    "    data['Giá']\n",
    "    .astype(str)\n",
    "    .str.replace(r'[^\\d]', '', regex=True)  # loại bỏ mọi ký tự không phải số\n",
    ")\n",
    "# Đổi chuỗi rỗng thành NaN\n",
    "data.loc[data['Giá'] == '', 'Giá'] = np.nan\n",
    "# Ép kiểu float và chia cho 1,000,000 để ra đơn vị triệu\n",
    "data['Giá'] = data['Giá'].astype(float) / 1_000_000 \n",
    "\n",
    "for col in ['Khoảng giá min', 'Khoảng giá max']:\n",
    "    data[col] = (\n",
    "        data[col]\n",
    "        .astype(str)\n",
    "        .str.replace('tr', '', case=False, regex=False)  # bỏ chữ \"tr\"\n",
    "        .str.replace(',', '.')  # nếu có dấu phẩy\n",
    "        .str.strip()  # bỏ khoảng trắng\n",
    "    )\n",
    "\n",
    "    # Đổi chuỗi rỗng thành NaN rồi ép kiểu float\n",
    "    data.loc[data[col] == '', col] = np.nan\n",
    "    data[col] = data[col].astype(float)\n",
    "###############################\n",
    "data_clean = data.copy()\n",
    "# 1. Xóa dòng thiếu tiêu đề hoặc giá\n",
    "data_clean = data_clean.dropna(subset=['Tiêu đề', 'Giá'])\n",
    "\n",
    "# 2. Điền khoảng giá min/max bằng cột Giá\n",
    "data_clean['Khoảng giá min'] = data_clean['Khoảng giá min'].fillna(data_clean['Giá'])\n",
    "data_clean['Khoảng giá max'] = data_clean['Khoảng giá max'].fillna(data_clean['Giá'])\n",
    "\n",
    "# 3. Nếu vẫn còn NaN, điền median theo Thương hiệu\n",
    "data_clean['Khoảng giá min'] = data_clean.groupby('Thương hiệu')['Khoảng giá min'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "data_clean['Khoảng giá max'] = data_clean.groupby('Thương hiệu')['Khoảng giá max'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "#############################################################\n",
    "\n",
    "def price_segment(price):\n",
    "    \"\"\"\n",
    "    Phân loại xe theo phân khúc giá.\n",
    "    - Phổ thông: < 70 triệu\n",
    "    - Cận cao cấp: 70–200 triệu\n",
    "    - Cao cấp: > 200 triệu\n",
    "    \"\"\"\n",
    "    if price < 70:\n",
    "        return \"Phổ thông\"\n",
    "    elif price < 200:\n",
    "        return \"Cận cao cấp\"\n",
    "    else:\n",
    "        return \"Cao cấp\"\n",
    "\n",
    "data_clean[\"Phân khúc giá\"] = data_clean[\"Giá\"].apply(price_segment)\n",
    "##############################################################\n",
    "\n",
    "# Chuyển về numeric\n",
    "data_clean[['Giá', 'Khoảng giá min', 'Khoảng giá max']] = data_clean[\n",
    "    ['Giá', 'Khoảng giá min', 'Khoảng giá max']\n",
    "].astype(float)\n",
    "# Lọc bỏ các giá bất thường\n",
    "data_clean = data_clean[(data_clean['Giá'] > 1) & (data_clean['Giá'] < 5000)]\n",
    "################################################################\n",
    "\n",
    "# Xử lý cột Số Km đã đi\n",
    "data_clean.loc[data_clean['Số Km đã đi'] > 99999, 'Số Km đã đi'] = 99999\n",
    "################################################################\n",
    "\n",
    "\n",
    "# Làm sạch text\n",
    "for col in ['Thương hiệu', 'Dòng xe', 'Loại xe', 'Dung tích xe', 'Xuất xứ', 'Phân khúc giá']:\n",
    "    data_clean[col] = data_clean[col].str.strip().str.title()\n",
    "\n",
    "# Dung tích xe: map định lượng\n",
    "def parse_cc(val):\n",
    "    if 'Dưới' in val: return 40\n",
    "    if '50 - 100' in val: return 75\n",
    "    if '100 - 175' in val: return 137\n",
    "    if 'Trên 175' in val: return 200\n",
    "    return np.nan\n",
    "data_clean['cc_numeric'] = data_clean['Dung tích xe'].apply(parse_cc)\n",
    "######################################################################\n",
    "\n",
    "# Phân khúc giá: map ordinal\n",
    "price_segment_map = {'Phổ Thông': 1, 'Cận Cao Cấp': 2, 'Cao Cấp': 3}\n",
    "data_clean['price_segment_code'] = data_clean['Phân khúc giá'].map(price_segment_map)\n",
    "#######################################################################\n",
    "\n",
    "# Thay các giá trị đặc biệt trong cột Năm đăng ký\n",
    "data_clean['Năm đăng ký'] = data_clean['Năm đăng ký'].replace({\n",
    "    'trước năm 1980': '1979',\n",
    "    'Đang cập nhật': np.nan,\n",
    "    'Không rõ': np.nan\n",
    "})\n",
    "# Chuyển sang kiểu int\n",
    "data_clean['Năm đăng ký'] = pd.to_numeric(data_clean['Năm đăng ký'], errors='coerce')\n",
    "data_clean['Năm đăng ký'] = data_clean['Năm đăng ký'].astype(int)\n",
    "\n",
    "min_age = 0.5  # tính tròn cho 6 tháng\n",
    "data_clean['age'] = 2025 - data_clean['Năm đăng ký']\n",
    "\n",
    "# Thay age == 0 bằng min_age\n",
    "data_clean.loc[data_clean['age'] <= 0, 'age'] = min_age\n",
    "#######################################################################\n",
    "\n",
    "# Xử lý missing values cho cột cc_numeric\n",
    "_processor.handle_missing_values_by_median('cc_numeric', data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2638481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"Giá\", \"Khoảng giá min\", \"Khoảng giá max\",\n",
    "    \"Số Km đã đi\", \"age\", \"cc_numeric\"]\n",
    "\n",
    "\n",
    "# Danh sách thương hiệu mô tô cao cấp\n",
    "premium_brands = ['BMW', 'Harley Davidson', 'Ducati', 'Triumph', 'Kawasaki', 'Benelli']\n",
    "\n",
    "# Áp dụng ngưỡng giá tối đa cho xe phổ thông\n",
    "data_clean.loc[\n",
    "    (~data_clean['Thương hiệu'].isin(premium_brands)) & (data_clean['Giá'] > 300),\n",
    "    'Giá'\n",
    "] = 300\n",
    "\n",
    "# Phát hiện outliers sử dụng IQR\n",
    "Q1 = data_clean[numeric_cols].quantile(0.25)\n",
    "Q3 = data_clean[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_mask = (data_clean[numeric_cols] < (Q1 - 1.5 * IQR)) | (data_clean[numeric_cols] > (Q3 + 1.5 * IQR))\n",
    "outlier_counts = outlier_mask.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c3cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa các nhóm keyword\n",
    "\n",
    "# Nhóm 1: MỚI / TÌNH TRẠNG XE\n",
    "kw_moi = [\n",
    "    \"mới\", \"còn mới\", \"như mới\", \"mới 95\", \"mới 99\", \"mới tinh\",\n",
    "    \"xe lướt\", \"xe ít đi\", \"ít sử dụng\", \"xe để không\", \"để kho\",\n",
    "    \"keng\", \"leng keng\", \"nguyên zin\", \"zin 100%\", \"zin nguyên bản\",\n",
    "    \"dán keo\", \"dán ppf\", \"ngoại hình đẹp\", \"dàn áo liền lạc\", \"đẹp như hình\"\n",
    "]\n",
    "# Nhóm 2: ĐỘ XE / ĐỒ CHƠI / NÂNG CẤP\n",
    "kw_do_xe = [\n",
    "    \"độ\", \"đồ chơi\", \"full đồ\", \"pô độ\", \"pô móc\", \"phuộc rcb\", \"tay thắng\",\n",
    "    \"lên đồ\", \"tem độ\", \"lên full đồ\", \"đồ zin còn đủ\", \"kính gió\", \"thùng givi\",\n",
    "    \"ốc titan\", \"mão gió\", \"bao tay\", \"trợ lực\", \"độ máy\"\n",
    "]\n",
    "# Nhóm 3: MỨC ĐỘ SỬ DỤNG\n",
    "kw_su_dung = [\n",
    "    \"ít đi\", \"đi làm\", \"đi học\", \"đi phượt\", \"đi cà phê\", \"để không\",\n",
    "    \"ít sử dụng\", \"xe gia đình\", \"xe công ty\", \"dư xe\", \"đi lại nhẹ nhàng\",\n",
    "    \"xe nữ dùng\", \"xe nữ chạy\", \"xe để lâu\", \"ít chạy\", \"đi gần\"\n",
    "]\n",
    "# Nhóm 4: BẢO DƯỠNG / SỬA CHỮA\n",
    "kw_bao_duong = [\n",
    "    \"bảo dưỡng\", \"bảo trì\", \"thay nhớt\", \"vệ sinh\", \"bao test\", \"đi bảo dưỡng\",\n",
    "    \"bảo dưỡng định kỳ\", \"mới thay bình\", \"mới làm nồi\", \"đã làm lại máy\",\n",
    "    \"thay bố thắng\", \"thay lọc\", \"bảo dưỡng lớn\", \"chỉnh sên\", \"xe kỹ\"\n",
    "]\n",
    "# Nhóm 5: ĐỘ BỀN / MÁY MÓC / CHẤT LƯỢNG\n",
    "kw_do_ben = [\n",
    "    \"máy êm\", \"nổ êm\", \"chạy êm\", \"máy mạnh\", \"máy bốc\", \"tiết kiệm xăng\",\n",
    "    \"ổn định\", \"chạy ngon\", \"không xì nhớt\", \"không rò rỉ\", \"không lỗi\",\n",
    "    \"máy khô ráo\", \"máy tốt\", \"chạy mượt\", \"vận hành ổn định\", \"êm ái\",\n",
    "    \"bền bỉ\", \"máy móc zin\", \"chạy bình thường\", \"hoạt động tốt\"\n",
    "]\n",
    "# Nhóm 6: GIẤY TỜ / PHÁP LÝ\n",
    "kw_phap_ly = [\n",
    "    \"chính chủ\", \"ủy quyền\", \"bao sang tên\", \"cà vẹt\", \"giấy tờ đầy đủ\",\n",
    "    \"giấy tờ hợp lệ\", \"hồ sơ gốc\", \"bstp\", \"bao công chứng\", \n",
    "    \"bao tranh chấp\", \"ra tên\", \"cavet\", \"hợp pháp\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6e3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm check từ khóa xuất hiện trong mô tả\n",
    "def keyword_flag(text: str, keywords: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Kiểm tra xem text có chứa ít nhất 1 từ khóa trong danh sách không.\n",
    "    Trả về 1 nếu có, 0 nếu không.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = text.lower()\n",
    "    return int(any(re.search(rf\"(?<!\\w){re.escape(kw)}(?!\\w)\", text) for kw in keywords))\n",
    "\n",
    "# Làm sạch và chuẩn hóa văn bản\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Chuẩn hóa mô tả:\n",
    "    - Chuyển về chữ thường\n",
    "    - Bỏ URL, ký tự đặc biệt, số\n",
    "    - Chuẩn hóa khoảng trắng\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Loại bỏ stopwords tiếng Việt\n",
    "vietnamese_stopwords = set([\n",
    "    \"xe\", \"máy\", \"bán\", \"cần\", \"mua\", \"báo\", \"liên\", \"hệ\", \"anh\", \"chị\",\n",
    "    \"em\", \"mn\", \"mọi\", \"người\", \"xin\", \"cảm\", \"ơn\", \"chợ\", \"tốt\", \"đầy\",\n",
    "    \"đủ\", \"điện\", \"thoại\", \"địa\", \"chỉ\", \"số\", \"của\", \"và\", \"với\", \"còn\",\n",
    "    \"thì\", \"nên\", \"rất\", \"đã\", \"được\", \"ko\", \"kg\", \"thật\", \"là\", \"thôi\",\n",
    "    \"nha\", \"nhé\", \"ạ\", \"nhưng\", \"bởi\", \"vì\", \"thì\", \"nào\", \"vậy\"\n",
    "])\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    words = text.split()\n",
    "    return \" \".join([w for w in words if w not in vietnamese_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c7768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áp dụng NLP\n",
    "data_clean[\"desc_clean\"] = data_clean[\"Mô tả chi tiết\"].apply(clean_text)\n",
    "data_clean[\"desc_clean\"] = data_clean[\"desc_clean\"].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "# Áp dụng tạo đặc trưng mới\n",
    "data_clean[\"is_moi\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_moi))\n",
    "data_clean[\"is_do_xe\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_do_xe))\n",
    "data_clean[\"is_su_dung_nhieu\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_su_dung))\n",
    "data_clean[\"is_bao_duong\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_bao_duong))\n",
    "data_clean[\"is_do_ben\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_do_ben))\n",
    "data_clean[\"is_phap_ly\"] = data_clean[\"desc_clean\"].apply(lambda x: keyword_flag(x, kw_phap_ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b42a84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_file = 'files/vietnamese-stopwords.txt'\n",
    "emojicon_file = 'files/emojicon.txt'\n",
    "teencode_file = 'files/teencode.txt'\n",
    "\n",
    "# Load stopwords, emojicons, teencode mappings\n",
    "with open(stop_word_file, 'r', encoding='utf-8') as f:\n",
    "    stopwords = set([w.strip() for w in f.readlines() if w.strip()])\n",
    "\n",
    "with open(emojicon_file, 'r', encoding='utf-8') as f:\n",
    "    emojicons = [w.strip() for w in f.readlines() if w.strip()]\n",
    "\n",
    "with open(teencode_file, 'r', encoding='utf-8') as f:\n",
    "    teencode_map = {}\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            teencode_map[parts[0]] = \" \".join(parts[1:])\n",
    "\n",
    "\n",
    "special_tokens = ['', ' ', ',', '.', '...', '-', ':', ';', '?', '%', '(', ')', '+', '/', \"'\", '&', '#', '*', '!', '\"', '_', '=', '[', ']', '{', '}', '~', '`', '|', '\\\\']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd50e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các hàm xử lý\n",
    "def remove_emojis(text):\n",
    "    for emo in emojicons:\n",
    "        text = text.replace(emo, ' ')\n",
    "    return text\n",
    "\n",
    "def normalize_teencode(text):\n",
    "    for key, val in teencode_map.items():\n",
    "        text = re.sub(rf'\\b{re.escape(key)}\\b', val, text)\n",
    "    return text\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # loại ký tự đặc biệt\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # loại khoảng trắng thừa\n",
    "    return text\n",
    "\n",
    "# -----------------------\n",
    "# 4. TÁCH STOPWORD RIÊNG\n",
    "# -----------------------\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text, format=\"text\").split()\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# -----------------------\n",
    "# 5. CHUẨN HÓA TỔNG HỢP\n",
    "# -----------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = remove_emojis(text)\n",
    "    text = normalize_teencode(text)\n",
    "    text = remove_special_chars(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['Content'] = data_clean['Mô tả chi tiết'].apply(lambda x: ' '.join(x.split()[:200]))\n",
    "\n",
    "data_clean['clean_text'] = data_clean['Content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "752d8bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Tiêu đề', 'Giá', 'Khoảng giá min', 'Khoảng giá max',\n",
       "       'Mô tả chi tiết', 'Thương hiệu', 'Dòng xe', 'Năm đăng ký',\n",
       "       'Số Km đã đi', 'Loại xe', 'Dung tích xe', 'Xuất xứ', 'Phân khúc giá',\n",
       "       'cc_numeric', 'price_segment_code', 'age', 'desc_clean', 'is_moi',\n",
       "       'is_do_xe', 'is_su_dung_nhieu', 'is_bao_duong', 'is_do_ben',\n",
       "       'is_phap_ly', 'Content', 'clean_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014155f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    max_features=8000\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(data_clean['clean_text'])\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def recommend(item_id: int, top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Recommend similar motorbikes based on cosine similarity.\n",
    "    Args:\n",
    "        item_id (int): id hoặc index của xe trong DataFrame\n",
    "        top_n (int): số lượng gợi ý muốn lấy\n",
    "    Returns:\n",
    "        DataFrame chứa các xe tương tự\n",
    "    \"\"\"\n",
    "    if item_id not in data.index:\n",
    "        raise ValueError(f\"id {item_id} không tồn tại trong DataFrame\")\n",
    "\n",
    "    # Lấy hàng tương ứng trong ma trận cosine\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[item_id]))\n",
    "\n",
    "    # Sắp xếp theo độ tương đồng giảm dần, bỏ chính nó\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1: top_n + 1]\n",
    "\n",
    "    # Lấy index xe tương tự\n",
    "    similar_indices = [i[0] for i in sim_scores]\n",
    "    similar_scores = [i[1] for i in sim_scores]\n",
    "\n",
    "    # Tạo DataFrame kết quả\n",
    "    recommendations = data.loc[similar_indices, ['id', 'Tiêu đề', 'Content']].copy()\n",
    "    recommendations['similarity'] = similar_scores\n",
    "    return recommendations.reset_index(drop=True)\n",
    "\n",
    "def recommend_cosine_by_text(query: str, top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Gợi ý xe máy tương tự dựa trên văn bản người dùng nhập vào.\n",
    "    \n",
    "    Args:\n",
    "        query (str): văn bản tìm kiếm\n",
    "        top_n (int): số lượng gợi ý\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: danh sách xe tương tự + độ tương đồng\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Tiền xử lý query bằng hàm clean_text của bạn\n",
    "    clean_query = clean_text(query)\n",
    "\n",
    "    # 2. Vector hóa query\n",
    "    query_vec = vectorizer.transform([clean_query])\n",
    "\n",
    "    # 3. Tính độ tương đồng cosine giữa query và toàn bộ item\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "\n",
    "    # 4. Lấy top N kết quả cao nhất\n",
    "    top_idx = sims.argsort()[::-1][:top_n]\n",
    "    top_scores = sims[top_idx]\n",
    "\n",
    "    # 5. Trả về DataFrame kết quả\n",
    "    result = data.iloc[top_idx][['id', 'Tiêu đề', 'Content']].copy()\n",
    "    result[\"similarity\"] = top_scores\n",
    "\n",
    "    return result.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f9014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
