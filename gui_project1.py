# GUI_Project1_fixed.py
# Fixed Streamlit app with robust AgGrid handling, post_time normalization,
# ensured post_id on load, and fully fixed admin approve/reject flows.
from io import BytesIO
import os
import uuid
import streamlit as st
import pandas as pd
import numpy as np
import joblib

# local utils (must be in same folder)
from utils_clean_data import clean_motobike_data
from utils_anomaly import run_price_anomaly_detection_with_reason

# ================== CONFIG & PATHS ==================
st.set_page_config(page_title="Ch·ª£ xe m√°y c≈©", layout="centered")
st.image("mua-ban-xe-may-cu-0.png", use_container_width=True)
st.title("üîÆ D·ª± ƒëo√°n gi√° & Ph√°t hi·ªán gi√° b·∫•t th∆∞·ªùng ‚Äî Xe m√°y c≈©")
st.markdown("Ch·ª£ xe m√°y c≈© t√≠ch h·ª£p ƒë·∫ßy ƒë·ªß ch·ª©c nƒÉng d·ª± ƒëo√°n gi√° xe m√°y c≈©, ph√°t hi·ªán gi√° b·∫•t th∆∞·ªùng, ƒëƒÉng tin b√°n/mua.")

DEFAULT_DATA = "data_motobikes.xlsx"
MODEL_PATH = "model_randomforest.pkl"

# Persist as Excel files (user requested Excel)
POSTS_SELL_XLSX = "posts_sell.xlsx"
POSTS_BUY_XLSX = "posts_buy.xlsx"
APPROVED_SELL_XLSX = "approved_posts_for_sale.xlsx"
APPROVED_BUY_XLSX = "approved_posts_for_buy.xlsx"
REJECTED_XLSX = "rejected_posts.xlsx"
QTV_ACCOUNTS = {
    "admin": "123456",
    "qtv1": "password1",
    "qtv2": "abc123"
}
# feature lists
num_cols = ['price_min', 'price_max', 'year_reg', 'km_driven', 'cc_numeric', 'price_segment_code', 'age']
flag_cols = ["is_moi", "is_do_xe", "is_su_dung_nhieu", "is_bao_duong", "is_do_ben", "is_phap_ly"]
cat_cols = ["brand", "vehicle_type", "model", "origin", "segment", 'engine_size']

BRANDS = ['Aprilia','Bmw','Bazan','Benelli','Brixton','Cr&S','Daelim','Detech','Ducati','Gpx','Halim',
          'Harley Davidson','Honda','Hyosung','H√£ng Kh√°c','Ktm','Kawasaki','Keeway','Kengo','Kymco',
          'Moto Guzzi','Nioshima','Peugeot','Piaggio','Rebelusa','Royal Enfield','Sym','Sachs','Sanda',
          'Suzuki','Taya','Triumph','Vento','Victory','Vinfast','Visitor','Yamaha']

# ================== HELPERS ==================
@st.cache_resource
def load_pipeline(path=MODEL_PATH):
    try:
        return joblib.load(path)
    except Exception as e:
        st.warning(f"Kh√¥ng load ƒë∆∞·ª£c model t·ª´ `{path}`: {e}")
        return None

def qtv_login():
    st.subheader("üîê ƒêƒÉng nh·∫≠p qu·∫£n tr·ªã vi√™n (QTV)")

    user = st.text_input("ID QTV:", key="qtv_user")
    pw = st.text_input("M·∫≠t kh·∫©u:", type="password", key="qtv_pw")

    if st.button("ƒêƒÉng nh·∫≠p", key="qtv_login_btn"):
        if user in QTV_ACCOUNTS and pw == QTV_ACCOUNTS[user]:
            st.session_state["qtv_logged_in"] = True
            st.success("ƒêƒÉng nh·∫≠p th√†nh c√¥ng!")
            st.rerun()
        else:
            st.error("Sai ID ho·∫∑c m·∫≠t kh·∫©u!")

def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8")


def df_to_excel_bytes(df: pd.DataFrame) -> bytes:
    bio = BytesIO()
    try:
        with pd.ExcelWriter(bio, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="posts")
        return bio.getvalue()
    except Exception:
        return df_to_csv_bytes(df)


def _read_xlsx_if_exists(path):
    if os.path.exists(path):
        try:
            return pd.read_excel(path)
        except Exception:
            return pd.DataFrame()
    return pd.DataFrame()


def _save_xlsx(df, path):
    try:
        # Ensure directory exists
        dirp = os.path.dirname(path)
        if dirp and not os.path.exists(dirp):
            os.makedirs(dirp, exist_ok=True)
        with pd.ExcelWriter(path, engine="openpyxl") as writer:
            df.to_excel(writer, index=False)
        return True
    except Exception as e:
        st.error(f"L·ªói khi l∆∞u file {path}: {e}")
        return False


def safe_prepare_X(df: pd.DataFrame) -> pd.DataFrame:
    dfc = df.copy()
    for c in num_cols + flag_cols + cat_cols:
        if c not in dfc.columns:
            if c in flag_cols:
                dfc[c] = 0
            elif c in num_cols:
                dfc[c] = 0.0
            else:
                dfc[c] = ""
    for n in ["km_driven", "cc_numeric", "age", "price_segment_code", "year_reg", "price_min", "price_max"]:
        if n in dfc.columns:
            dfc[n] = pd.to_numeric(dfc[n], errors="coerce").fillna(0.0)
    for f in flag_cols:
        if f in dfc.columns:
            dfc[f] = dfc[f].apply(lambda x: 1 if (str(x).lower() in ["1","true","yes","c√≥","co"]) or x==1 or x is True else 0).astype(int)
    return dfc


def compute_risk_score_strict(row, last_clean_brand_models=None, anomaly_reason=None):
    score = 0.0
    try:
        price = float(row.get("price", 0.0))
        pred = float(row.get("predicted_price", 0.0))
        if pred > 0:
            diff_pct = abs(price - pred) / pred
            score += min(50.0, diff_pct * 100.0 * 0.5)
    except Exception:
        pass
    if anomaly_reason and isinstance(anomaly_reason, str) and anomaly_reason != "Kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng":
        score += 25.0
    try:
        km = float(row.get("km_driven", 0.0))
        age = float(row.get("age", 0.0))
        if age >= 5 and km < 2000:
            score += 20.0
        elif age >= 8 and km < 5000:
            score += 30.0
    except Exception:
        pass
    try:
        if int(row.get("is_moi", 0)) == 1 and float(row.get("age", 0.0)) > 3:
            score += 10.0
    except Exception:
        pass
    if last_clean_brand_models and isinstance(last_clean_brand_models, dict):
        brand = str(row.get("brand", "")).strip()
        model = str(row.get("model", "")).strip()
        if brand in last_clean_brand_models:
            known_models = last_clean_brand_models.get(brand, [])
            if model and (model not in known_models):
                score += 30.0
    score = min(100.0, score)
    return round(score, 2)


def risk_level_from_score(score):
    if score >= 70:
        return "Nguy hi·ªÉm"
    elif score >= 40:
        return "ƒê√°ng ch√∫ √Ω"
    else:
        return "An to√†n"


def make_post_record(df_row: pd.DataFrame, post_type: str, chosen_price: float, user_id: str = "anonymous", note: str = ""):
    rec = df_row.iloc[0].to_dict()
    rec["post_id"] = str(uuid.uuid4())[:8]
    rec["post_time"] = pd.Timestamp.now()
    rec["post_type"] = post_type
    rec["price_input"] = rec.get("price", np.nan)
    rec["price_pred"] = rec.get("predicted_price", np.nan)
    rec["price_final"] = chosen_price
    rec["status"] = "pending"
    rec["user_id"] = user_id
    rec["note"] = note
    rec["anomaly_reason"] = rec.get("anomaly_reason", "")
    rec["risk_score"] = rec.get("risk_score", np.nan)
    return rec


def ensure_post_id(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if out is None or out.empty:
        return out
    if "post_id" not in out.columns:
        out["post_id"] = [str(uuid.uuid4())[:8] for _ in range(len(out))]
    # ensure dtype str
    out["post_id"] = out["post_id"].astype(str)
    return out


def normalize_datetime_like_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if out is None or out.empty:
        return out
    for col in out.columns:
        try:
            if pd.api.types.is_datetime64_any_dtype(out[col]):
                out[col] = out[col].astype(str)
        except Exception:
            # ignore problematic columns
            pass
    return out


def prepare_for_aggrid(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if out is None or out.empty:
        return out
    # convert datetime-like columns to string
    out = normalize_datetime_like_columns(out)
    # convert object columns to str (except post_id)
    for col in out.columns:
        if col != "post_id" and out[col].dtype == object:
            out[col] = out[col].astype(str)
    return out


def save_post_record(record: dict):
    df_new = pd.DataFrame([record])
    if record.get("post_type") == "sell":
        posts = _read_xlsx_if_exists(POSTS_SELL_XLSX)
        posts = pd.concat([posts, df_new], ignore_index=True)
        posts = ensure_post_id(posts)
        _save_xlsx(posts, POSTS_SELL_XLSX)
        st.session_state["posts_sell"] = posts.copy()
    else:
        posts = _read_xlsx_if_exists(POSTS_BUY_XLSX)
        posts = pd.concat([posts, df_new], ignore_index=True)
        posts = ensure_post_id(posts)
        _save_xlsx(posts, POSTS_BUY_XLSX)
        st.session_state["posts_buy"] = posts.copy()
    st.session_state.setdefault("pending_notifications", [])
    st.session_state["pending_notifications"].append(record.get("post_id"))


def rename_columns_vn(df: pd.DataFrame, mode="general"):
    """
    mode = "sell"  -> Gi√° b√°n
    mode = "buy"   -> Gi√° mua
    mode = "general" -> Gi√° b√°n / Gi√° mua (d√πng cho QTV)
    """

    if mode == "sell":
        price_name = "Gi√° b√°n"
    elif mode == "buy":
        price_name = "Gi√° mua"
    else:
        price_name = "Gi√° b√°n / Gi√° mua"

    col_map = {
        "selected": "Ch·ªçn",
        "user_id": "ID ng∆∞·ªùi d√πng",
        "note": "M√¥ t·∫£",
        "price_final": price_name,
        "year_reg": "NƒÉm ƒëƒÉng k√Ω",
        "km_driven": "Km ƒë√£ ƒëi",
        "brand": "H√£ng xe",
        "model": "D√≤ng xe",
        "cc_numeric": "Dung t√≠ch xe (cc)",
        "origin": "Xu·∫•t x·ª©",
        "vehicle_type": "Lo·∫°i xe",
    }
    df = df.rename(columns=col_map)
    return df

def reorder_columns(df: pd.DataFrame):
    front_cols = ["selected", "user_id", "note"]
    other_cols = [c for c in df.columns if c not in front_cols]
    return df[front_cols + other_cols]

# ================== LOAD PIPELINE ==================
pipeline = load_pipeline(MODEL_PATH)

# ================== SESSION STATE & PERSISTENT LOAD ==================
if "last_clean" not in st.session_state:
    st.session_state["last_clean"] = None
if "predicted_df" not in st.session_state:
    st.session_state["predicted_df"] = None
if "last_predict" not in st.session_state:
    st.session_state["last_predict"] = None

# load persisted posts from excel if exist (ensure post_id & normalize datetimes)
if "posts_sell" not in st.session_state:
    posts = _read_xlsx_if_exists(POSTS_SELL_XLSX)
    posts = ensure_post_id(posts)
    posts = normalize_datetime_like_columns(posts)
    st.session_state["posts_sell"] = posts
if "posts_buy" not in st.session_state:
    posts = _read_xlsx_if_exists(POSTS_BUY_XLSX)
    posts = ensure_post_id(posts)
    posts = normalize_datetime_like_columns(posts)
    st.session_state["posts_buy"] = posts
if "pending_notifications" not in st.session_state:
    st.session_state["pending_notifications"] = []

# ================== AUTO LOAD DEFAULT DATA + PREDICT (runs once per session) ==================
if st.session_state.get("predicted_df") is None:
    if os.path.exists(DEFAULT_DATA):
        try:
            raw = pd.read_excel(DEFAULT_DATA)
            data_clean = clean_motobike_data(raw)
            if "age" in data_clean.columns:
                data_clean["age"] = data_clean["age"].astype(float, errors="ignore")
            st.session_state["last_clean"] = data_clean.copy()
            X_df = safe_prepare_X(data_clean)
            feats = [c for c in (num_cols + flag_cols + cat_cols) if c in X_df.columns]
            if pipeline is not None and len(feats) > 0:
                preds = pipeline.predict(X_df[feats])
                data_clean = data_clean.copy()
                data_clean["price_pred"] = np.round(preds, 2)
                st.session_state["predicted_df"] = data_clean
            else:
                st.warning("Model ch∆∞a ƒë∆∞·ª£c load ho·∫∑c thi·∫øu features; predicted_df kh√¥ng c√≥.")
        except Exception as e:
            st.error(f"L·ªói khi auto load/clean/predict default data: {e}")
    else:
        st.warning(f"Kh√¥ng t√¨m th·∫•y file m·∫∑c ƒë·ªãnh: {DEFAULT_DATA}.")

# ================== MENU ==================
menu = [
    "Home",
    "D·ª± ƒëo√°n gi√° xe m√°y",
    "ƒêƒÉng b√°n",
    "ƒêƒÉng mua",
    "Ph√°t hi·ªán xe m√°y b·∫•t th∆∞·ªùng",
    "Duy·ªát tin (QTV)",
    "Th√¥ng tin t√°c gi·∫£"
]
choice = st.sidebar.selectbox("üìå MENU", menu)

# ------------------ PAGES ------------------
if choice == "Home":
    st.header("üè† Home")
    st.write("""
            ‚úî D·ª± ƒëo√°n gi√° xe - G·ª£i √Ω gi√° b√°n/mua h·ª£p l√Ω
             
            ‚úî Cho ph√©p ng∆∞·ªùi d√πng ƒëƒÉng tin b√°n/mua xe m√°y c≈©
                      
            ‚úî Ph√°t hi·ªán xe ƒëƒÉng b√°n v·ªõi gi√° b·∫•t th∆∞·ªùng
             
            ‚úî T·ª± ƒë·ªông ph√¢n t√≠ch m√¥ t·∫£ & ph√°t hi·ªán d·∫•u hi·ªáu ƒë√°ng ng·ªù  
    """)

# ------------------ PREDICTION PAGE ------------------
elif choice == "D·ª± ƒëo√°n gi√° xe m√°y":
    st.header("üìà D·ª± ƒëo√°n gi√° xe m√°y")

    st.subheader("A. K·∫øt qu·∫£ model (d·ªØ li·ªáu m·∫´u t·ª± load)")
    pred_df = st.session_state.get("predicted_df")
    if pred_df is None:
        st.warning("D·ªØ li·ªáu m·∫´u ch∆∞a ƒë∆∞·ª£c load ho·∫∑c model ch∆∞a ƒë∆∞·ª£c t√≠nh.")
    else:
        if st.button("üìÑ Hi·ªÉn th·ªã 10 xe m√°y m·∫´u ƒë√£ ƒë∆∞·ª£c model d·ª± ƒëo√°n", key="show_sample_10"):
            show_cols = [c for c in ["brand", "model", "year_reg", "km_driven", "cc_numeric", "price", "price_pred"] if c in pred_df.columns]
            st.dataframe(pred_df[show_cols].head(10).reset_index(drop=True))
            st.download_button("‚¨áÔ∏è T·∫£i to√†n b·ªô k·∫øt qu·∫£ d·ª± ƒëo√°n (Excel)", df_to_excel_bytes(pred_df), file_name="predicted_sample.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    st.markdown("---")
    st.subheader("B. Nh·∫≠p tay ƒë·ªÉ g·ª£i √Ω gi√° (d·ª±a tr√™n model ƒë√£ load)")
    last = st.session_state.get("last_clean")

    brands_opts = sorted(last["brand"].dropna().unique().tolist()) if last is not None and "brand" in last.columns else BRANDS
    models_opts = sorted(last["model"].dropna().unique().tolist()) if last is not None and "model" in last.columns else ["Wave","Exciter","Sirius"]
    vehicle_types_opts = sorted(last["vehicle_type"].dropna().unique().tolist()) if last is not None and "vehicle_type" in last.columns else ["Xe s·ªë","Xe tay ga","Xe c√¥n"]
    origin_opts = sorted(last["origin"].dropna().unique().tolist()) if last is not None and "origin" in last.columns else ["Vi·ªát Nam","Nh·∫≠p Kh·∫©u"]
    segment_opts = sorted(last["segment"].dropna().unique().tolist()) if last is not None and "segment" in last.columns else ["Ph·ªï th√¥ng","C·∫≠n cao c·∫•p","Cao c·∫•p"]

    price = st.number_input("Gi√° mong mu·ªën (tri·ªáu VND)", min_value=0.0, value=10.0, step=0.1, key="inp_price")
    price_min = st.number_input("Kho·∫£ng gi√° min (tri·ªáu VND)", min_value=0.0, value=8.0, step=0.1, key="inp_price_min")
    price_max = st.number_input("Kho·∫£ng gi√° max (tri·ªáu VND)", min_value=0.0, value=12.0, step=0.1, key="inp_price_max")
    engine_size_sel = st.selectbox("Dung t√≠ch xe (nh√£n)", options=["D∆∞·ªõi 50","50 - 100","100 - 175","Tr√™n 175"], index=2, key="inp_engine_size")
    col1, col2 = st.columns(2)
    with col1:
        brand_inp = st.selectbox("Th∆∞∆°ng hi·ªáu (brand)", options=brands_opts, key="inp_brand")
        model_inp = st.selectbox("D√≤ng xe (model)", options=models_opts, key="inp_model")
        vehicle_type_inp = st.selectbox("Lo·∫°i xe (vehicle_type)", options=vehicle_types_opts, key="inp_vehicle_type")
    with col2:
        km_driven = st.number_input("S·ªë Km ƒë√£ ƒëi (km_driven)", min_value=0, step=1, value=1000, key="inp_km")
        cc_numeric = st.number_input("Dung t√≠ch numeric (cc_numeric)", min_value=0, step=1, value=137, key="inp_cc")
        age = st.number_input("Tu·ªïi xe (age)", min_value=0.1, step=0.1, value=3.0, format="%.1f", key="inp_age")

    st.markdown("**T√¨nh tr·∫°ng (Tick = C√≥ / Kh√¥ng = Kh√¥ng)**")
    r1c1, r1c2, r1c3 = st.columns(3)
    with r1c1:
        is_moi = st.checkbox("Xe c√≤n m·ªõi", value=False, key="inp_is_moi")
    with r1c2:
        is_do_xe = st.checkbox("C√≥ ƒë·ªô xe", value=False, key="inp_is_do_xe")
    with r1c3:
        is_su_dung_nhieu = st.checkbox("Xe ƒëi nhi·ªÅu", value=False, key="inp_is_su_dung_nhieu")
    r2c1, r2c2, r2c3 = st.columns(3)
    with r2c1:
        is_bao_duong = st.checkbox("Xe c√≥ b·∫£o d∆∞·ª°ng", value=False, key="inp_is_bao_duong")
    with r2c2:
        is_do_ben = st.checkbox("M√°y xe c√≤n t·ªët", value=False, key="inp_is_do_ben")
    with r2c3:
        is_phap_ly = st.checkbox("Ph√°p l√Ω r√µ r√†ng", value=True, key="inp_is_phap_ly")

    origin_inp = st.selectbox("Xu·∫•t x·ª© (origin)", options=origin_opts, key="inp_origin")
    segment_inp = st.selectbox("Ph√¢n kh√∫c (segment)", options=segment_opts, key="inp_segment")
    segment_map = {"Ph·ªï th√¥ng": 1, "C·∫≠n cao c·∫•p": 2, "Cao c·∫•p": 3}
    price_segment_code = segment_map.get(segment_inp, 1)
    suggestion_type = st.radio("Ch·ªçn lo·∫°i g·ª£i √Ω", ("G·ª£i √Ω gi√° b√°n", "G·ª£i √Ω gi√° mua h·ª£p l√Ω"), key="inp_suggestion_type")

    # Save inputs to session so they're not lost on rerun
    st.session_state["inputs_last"] = {
        "price": price, "price_min": price_min, "price_max": price_max,
        "engine_size_sel": engine_size_sel, "brand_inp": brand_inp, "model_inp": model_inp,
        "vehicle_type_inp": vehicle_type_inp, "km_driven": km_driven, "cc_numeric": cc_numeric,
        "age": age, "is_moi": is_moi, "is_do_xe": is_do_xe, "is_su_dung_nhieu": is_su_dung_nhieu,
        "is_bao_duong": is_bao_duong, "is_do_ben": is_do_ben, "is_phap_ly": is_phap_ly,
        "origin_inp": origin_inp, "segment_inp": segment_inp, "price_segment_code": price_segment_code,
        "suggestion_type": suggestion_type
    }

    # --- PREDICT BUTTON: compute and STORE prediction in session_state ---
    predict_clicked = st.button("üîç D·ª± ƒëo√°n / G·ª£i √Ω", key="btn_predict")
    if predict_clicked:
        row = {
            "price": price,
            "price_min": price_min,
            "price_max": price_max,
            "km_driven": km_driven,
            "engine_size": engine_size_sel,
            "cc_numeric": cc_numeric,
            "age": age,
            "year_reg": int(max(1900, 2025 - age)),
            "price_segment_code": price_segment_code,
            "is_moi": int(is_moi),
            "is_do_xe": int(is_do_xe),
            "is_su_dung_nhieu": int(is_su_dung_nhieu),
            "is_bao_duong": int(is_bao_duong),
            "is_do_ben": int(is_do_ben),
            "is_phap_ly": int(is_phap_ly),
            "brand": brand_inp,
            "vehicle_type": vehicle_type_inp,
            "model": model_inp,
            "origin": origin_inp,
            "segment": segment_inp
        }
        df_row = pd.DataFrame([row])
        # Save the row to session_state right away ‚Äî prevents loss after rerun
        st.session_state["last_predict"] = df_row.copy()

        df_row_prep = safe_prepare_X(df_row)
        X_row = df_row_prep[[c for c in (num_cols + flag_cols + cat_cols) if c in df_row_prep.columns]]
        if pipeline is None:
            st.error("Model ch∆∞a ƒë∆∞·ª£c load (model_randomforest.pkl).")
        else:
            try:
                pred = float(pipeline.predict(X_row)[0])
                st.session_state["last_predict"].loc[0, "predicted_price"] = round(pred, 2)
                try:
                    anomaly_res = run_price_anomaly_detection_with_reason(
                        data=df_row_prep.assign(price=df_row.loc[0,"price"]),
                        trained_model=pipeline,
                        num_cols=num_cols,
                        flag_cols=flag_cols,
                        cat_cols=cat_cols,
                        seg_col="price_segment_code",
                        k=0.05
                    )
                    anomaly_reason = anomaly_res.loc[0, "anomaly_reason"] if "anomaly_reason" in anomaly_res.columns else "Kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng"
                except Exception:
                    anomaly_reason = "Kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng"
                st.session_state["last_predict"].loc[0, "anomaly_reason"] = anomaly_reason
                last = st.session_state.get("last_clean")
                brand_model_map = {}
                if last is not None:
                    for b, g in last.groupby("brand"):
                        brand_model_map[b] = sorted(g["model"].dropna().unique().tolist())
                risk = compute_risk_score_strict(st.session_state["last_predict"].loc[0].to_dict(), last_clean_brand_models=brand_model_map, anomaly_reason=anomaly_reason)
                st.session_state["last_predict"].loc[0, "risk_score"] = risk
                st.session_state["last_predict"].loc[0, "risk_level"] = risk_level_from_score(risk)

                if suggestion_type == "G·ª£i √Ω gi√° b√°n":
                    st.success(f"üì¶ G·ª£i √Ω gi√° b√°n: **{pred:,.2f} tri·ªáu VND**")
                    st.info(f"Kho·∫£ng tham kh·∫£o: {pred*0.95:,.2f} ‚Äî {pred*1.05:,.2f} tri·ªáu")
                else:
                    buy_price = pred * 0.92
                    st.success(f"üõí G·ª£i √Ω gi√° mua h·ª£p l√Ω: **{buy_price:,.2f} tri·ªáu VND**")
                    st.info(f"(Gi√° model d·ª± ƒëo√°n = {pred:,.2f} tri·ªáu)")
            except Exception as e:
                st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")

    # --- OUTSIDE predict button: show ƒêƒÉng tin UI if there's a prediction stored ---
    saved = st.session_state.get("last_predict")
    if saved is not None:
        st.subheader("T√≥m t·∫Øt (b·∫£n ghi s·∫Ω l∆∞u n·∫øu b·∫°n X√°c nh·∫≠n ƒëƒÉng)")
        st.write(saved.T)

        st.markdown("### ƒêƒÉng tin")
        post_type_choice = st.radio("B·∫°n mu·ªën:", ("ƒêƒÉng b√°n", "ƒêƒÉng mua"), key="post_type_choice")
        price_choice = st.radio("Ch·ªçn gi√° ƒë·ªÉ ƒëƒÉng:", ("Gi·ªØ gi√° ƒë√£ nh·∫≠p", "D√πng gi√° d·ª± ƒëo√°n"), key="price_choice")
        chosen_price = float(saved.loc[0, "price"]) if price_choice == "Gi·ªØ gi√° ƒë√£ nh·∫≠p" else float(saved.loc[0, "predicted_price"])

        # text_input outside confirm button, persistent via key
        user_id = st.text_input("ID ng∆∞·ªùi ƒëƒÉng", value="", key="user_id")
        user_note= st.text_input("Ghi ch√∫", value="", key="user_note")

        if st.button("‚úÖ X√°c nh·∫≠n v√† g·ª≠i tin l√™n h·ªá th·ªëng", key="confirm_send"):
            ptype = "sell" if post_type_choice == "ƒêƒÉng b√°n" else "buy"
            record = make_post_record(saved, post_type=ptype, chosen_price=chosen_price, user_id=(user_id or "anonymous"), note=user_note)
            save_post_record(record)
            st.success("‚úÖ Tin c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c g·ª≠i l√™n h·ªá th·ªëng v√† ch·ªù QTV duy·ªát.")
            st.info("B·∫°n c√≥ th·ªÉ v√†o menu 'ƒêƒÉng b√°n' ho·∫∑c 'ƒêƒÉng mua' ƒë·ªÉ xem l·∫°i tin ƒë√£ g·ª≠i (ƒë∆∞·ª£c l∆∞u tr√™n server).")
            # do not rerun; keep last_predict for review/edit

# ------------------ ƒêƒÉng b√°n / ƒêƒÉng mua (user view) ------------------
elif choice == "ƒêƒÉng b√°n":
    st.header("üì¢ Tin ƒëƒÉng b√°n (Ng∆∞·ªùi d√πng)")
    # Show approved posts only
    posts = _read_xlsx_if_exists(APPROVED_SELL_XLSX)
    posts = normalize_datetime_like_columns(posts)
    if posts.empty:
        st.info("Hi·ªán ch∆∞a c√≥ tin ƒëƒÉng b√°n.")
    else:
        st.write(f"T·ªïng: {len(posts)} tin")
        show_cols = [
            "user_id", "note", "price_final", "year_reg",
            "km_driven", "brand", "model", "cc_numeric",
            "origin", "vehicle_type"
        ]

        posts_show = posts.copy()

        # Gi·ªØ ƒë√∫ng c·ªôt + ƒë·ªïi t√™n ti·∫øng Vi·ªát
        posts_show = posts_show[show_cols]
        posts_show = rename_columns_vn(posts_show)

        st.dataframe(posts_show.reset_index(drop=True), use_container_width=True)
        st.download_button("‚¨áÔ∏è T·∫£i tin ƒëƒÉng b√°n (Excel)", df_to_excel_bytes(posts), file_name="posts_sell.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

elif choice == "ƒêƒÉng mua":
    st.header("üì£ Tin ƒëƒÉng mua (Ng∆∞·ªùi d√πng)")
    posts = _read_xlsx_if_exists(APPROVED_BUY_XLSX)
    posts = normalize_datetime_like_columns(posts)
    if posts.empty:
        st.info("Hi·ªán ch∆∞a c√≥ tin ƒëƒÉng mua.")
    else:
        st.write(f"T·ªïng: {len(posts)} tin")
        show_cols = [
            "user_id", "note", "price_final", "year_reg",
            "km_driven", "brand", "model", "cc_numeric",
            "origin", "vehicle_type"
        ]

        posts_show = posts.copy()
        posts_show = posts_show[show_cols]
        posts_show = rename_columns_vn(posts_show)

        st.dataframe(posts_show.reset_index(drop=True), use_container_width=True)
        st.download_button("‚¨áÔ∏è T·∫£i tin ƒëƒÉng mua (Excel)", df_to_excel_bytes(posts), file_name="posts_buy.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ------------------ ANOMALY PAGE ------------------
elif choice == "Ph√°t hi·ªán xe m√°y b·∫•t th∆∞·ªùng":
    st.header("üö® Ph√°t hi·ªán xe m√°y b·∫•t th∆∞·ªùng")
    pred_df = st.session_state.get("predicted_df")
    st.subheader("A. K·∫øt qu·∫£ anomaly tr√™n d·ªØ li·ªáu m·∫´u (auto-run)")
    if pred_df is None:
        st.warning("D·ªØ li·ªáu m·∫´u ch∆∞a load ho·∫∑c model ch∆∞a predict.")
    else:
        if st.button("üìÑ Hi·ªÉn th·ªã 10 b·∫£n ghi c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng", key="show_anom_10"):
            try:
                df_for_anom = pred_df.copy()
                if "price" not in df_for_anom.columns:
                    st.error("D·ªØ li·ªáu m·∫´u thi·∫øu c·ªôt `price` ƒë·ªÉ ki·ªÉm tra anomaly.")
                else:
                    result_df = run_price_anomaly_detection_with_reason(
                        data=df_for_anom,
                        trained_model=pipeline,
                        num_cols=num_cols,
                        flag_cols=flag_cols,
                        cat_cols=cat_cols,
                        seg_col="price_segment_code",
                        k=0.05
                    )
                    anomalies = result_df[result_df["anomaly_reason"] != "Kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng"].copy()
                    if anomalies.empty:
                        st.info("Kh√¥ng t√¨m th·∫•y b·∫£n ghi b·∫•t th∆∞·ªùng trong d·ªØ li·ªáu m·∫´u.")
                    else:
                        anomalies_sorted = anomalies.sort_values(by="anomaly_score", ascending=False)
                        show_cols = [c for c in ["brand","model","year_reg","km_driven","price","price_pred_final","anomaly_score","anomaly_reason","anomaly_level"] if c in anomalies_sorted.columns]
                        st.dataframe(anomalies_sorted[show_cols].head(10).reset_index(drop=True))
                        st.download_button("‚¨áÔ∏è T·∫£i k·∫øt qu·∫£ b·∫•t th∆∞·ªùng (Excel)", df_to_excel_bytes(anomalies_sorted), file_name="anomalies_sample.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            except Exception as e:
                st.error(f"L·ªói khi ch·∫°y anomaly tr√™n d·ªØ li·ªáu m·∫´u: {e}")

    st.markdown("---")
    st.subheader("B. Nh·∫≠p tay ƒë·ªÉ ki·ªÉm tra 1 xe")
    price = st.number_input("Gi√° (tri·ªáu VND)", min_value=0.0, value=10.0, step=0.1, key="an_price")
    price_min = st.number_input("Kho·∫£ng gi√° min (tri·ªáu VND)", min_value=0.0, value=8.0, step=0.1, key="an_price_min")
    price_max = st.number_input("Kho·∫£ng gi√° max (tri·ªáu VND)", min_value=0.0, value=12.0, step=0.1, key="an_price_max")
    last = st.session_state.get("last_clean")
    brands_opts = sorted(last["brand"].dropna().unique().tolist()) if last is not None and "brand" in last.columns else BRANDS
    brand_sel = st.selectbox("Th∆∞∆°ng hi·ªáu", options=brands_opts, key="an_brand")
    model_sel = st.text_input("D√≤ng xe (D√≤ng xe)", value="Wave", key="an_model")
    year_reg = st.number_input("NƒÉm ƒëƒÉng k√Ω", min_value=1900, max_value=2025, value=2020, step=1, key="an_year_reg")
    age = 0.5 if 2025 - year_reg == 0 else 2025 - year_reg
    km_driven_an = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, value=5000, step=1, key="an_km")
    vehicle_type_sel = st.text_input("Lo·∫°i xe", value="Xe s·ªë", key="an_vehicle_type")
    engine_size_sel = st.selectbox("Dung t√≠ch xe (nh√£n)", options=["D∆∞·ªõi 50","50 - 100","100 - 175","Tr√™n 175"], index=2, key="an_engine_size")
    origin_sel = st.selectbox("Xu·∫•t x·ª©", options=["Vi·ªát Nam","Nh·∫≠p Kh·∫©u"], key="an_origin")
    segment_sel = st.selectbox("Ph√¢n kh√∫c gi√°", options=["Ph·ªï th√¥ng","C·∫≠n cao c·∫•p","Cao c·∫•p"], key="an_segment")
    segment_map = {"Ph·ªï Th√¥ng": 1, "C·∫≠n cao c·∫•p": 2, "Cao C·∫•p": 3}
    price_segment_code = segment_map.get(segment_sel, 1)

    st.markdown("**T√¨nh tr·∫°ng (Tick = C√≥ / Kh√¥ng = Kh√¥ng)**")
    a1, a2, a3 = st.columns(3)
    with a1:
        an_is_moi = st.checkbox("Xe c√≤n m·ªõi", value=False, key="an_is_moi")
    with a2:
        an_is_do_xe = st.checkbox("C√≥ ƒë·ªô xe", value=False, key="an_is_do_xe")
    with a3:
        an_is_su_dung_nhieu = st.checkbox("Xe ƒëi nhi·ªÅu", value=False, key="an_is_su_dung_nhieu")
    b1, b2, b3 = st.columns(3)
    with b1:
        an_is_bao_duong = st.checkbox("Xe c√≥ b·∫£o d∆∞·ª°ng", value=False, key="an_is_bao_duong")
    with b2:
        an_is_do_ben = st.checkbox("M√°y xe c√≤n t·ªët", value=False, key="an_is_do_ben")
    with b3:
        an_is_phap_ly = st.checkbox("Ph√°p l√Ω r√µ r√†ng", value=True, key="an_is_phap_ly")

    if st.button("Ki·ªÉm tra", key="an_check"):
        row = {
            "price": price,
            "price_min": price_min,
            "price_max": price_max,
            "brand": brand_sel,
            "model": model_sel,
            "year_reg": year_reg,
            "age": age,
            "km_driven": km_driven_an,
            "vehicle_type": vehicle_type_sel,
            "engine_size": engine_size_sel,
            "cc_numeric": 137,
            "origin": origin_sel,
            "segment": segment_sel,
            "is_moi": int(an_is_moi),
            "is_do_xe": int(an_is_do_xe),
            "is_su_dung_nhieu": int(an_is_su_dung_nhieu),
            "is_bao_duong": int(an_is_bao_duong),
            "is_do_ben": int(an_is_do_ben),
            "is_phap_ly": int(an_is_phap_ly),
            "price_segment_code": price_segment_code
        }
        df_row = pd.DataFrame([row])
        df_row_prep = safe_prepare_X(df_row)
        if pipeline is None:
            st.error("Model ch∆∞a ƒë∆∞·ª£c load (model_randomforest.pkl).")
        else:
            try:
                df_row["predicted_price"] = float(pipeline.predict(df_row_prep[[c for c in (num_cols + flag_cols + cat_cols) if c in df_row_prep.columns]])[0])
                res = run_price_anomaly_detection_with_reason(
                    data=df_row_prep.assign(price=row["price"]),
                    trained_model=pipeline,
                    num_cols=num_cols,
                    flag_cols=flag_cols,
                    cat_cols=cat_cols,
                    seg_col="price_segment_code",
                    k=0.05
                )
                st.markdown("### K·∫øt qu·∫£ ki·ªÉm tra")
                st.write("**Anomaly reason:**", res.loc[0, "anomaly_reason"])
                st.write("**Anomaly level:**", res.loc[0, "anomaly_level"])
                st.download_button("‚¨áÔ∏è T·∫£i k·∫øt qu·∫£ ki·ªÉm tra (Excel)", df_to_excel_bytes(df_row), file_name="anomaly_check_single.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            except Exception as e:
                st.error(f"L·ªói khi ki·ªÉm tra b·∫•t th∆∞·ªùng: {e}")

# ------------------ ADMIN (QTV) ------------------
elif choice == "Duy·ªát tin (QTV)":
    if "qtv_logged_in" not in st.session_state or st.session_state["qtv_logged_in"] is False:
        qtv_login()
        st.stop()
    
    st.header("üîß Duy·ªát tin ‚Äî Qu·∫£n tr·ªã vi√™n")

    pending = len(st.session_state.get("pending_notifications", []))
    st.markdown(f"**Tin ch·ªù duy·ªát:** {pending}")

    manage_sell = st.checkbox("Qu·∫£n l√Ω tin ƒëƒÉng b√°n", value=True)
    manage_buy = st.checkbox("Qu·∫£n l√Ω tin ƒëƒÉng mua", value=False)

    # ===========================
    #     X·ª¨ L√ù TIN ƒêƒÇNG B√ÅN
    # ===========================
    if manage_sell:

        st.subheader("üì¶ Tin ƒëƒÉng b√°n (ch·ªù duy·ªát)")

        df_sell = st.session_state.get("posts_sell", pd.DataFrame()).copy()

        if df_sell.empty:
            st.info("Kh√¥ng c√≥ tin ƒëƒÉng b√°n n√†o.")
        else:
            # Th√™m c·ªôt checkbox
            df_sell_display = df_sell.copy()
            df_sell_display["selected"] = False

            df_sell_display = reorder_columns(df_sell_display)
            df_sell_display = rename_columns_vn(df_sell_display, mode="sell")

            edited_sell = st.data_editor(
                df_sell_display,
                use_container_width=True,
                hide_index=True,
                key="editor_sell"
            )

            # Nh·ªØng d√≤ng ƒë∆∞·ª£c ch·ªçn
            selected_sell = edited_sell[edited_sell["Ch·ªçn"] == True]

            col1, col2 = st.columns(2)

            with col1:
                if st.button("‚úîÔ∏è Duy·ªát tin b√°n"):
                    if selected_sell.empty:
                        st.warning("Ch∆∞a ch·ªçn d√≤ng ƒë·ªÉ duy·ªát.")
                    else:
                        post_ids = selected_sell["post_id"].tolist()

                        # L∆∞u v√†o approved
                        approved = _read_xlsx_if_exists(APPROVED_SELL_XLSX)
                        approved = pd.concat(
                            [approved, df_sell[df_sell["post_id"].isin(post_ids)]],
                            ignore_index=True
                        )
                        _save_xlsx(approved, APPROVED_SELL_XLSX)

                        # x√≥a kh·ªèi pending
                        df_sell_new = df_sell[~df_sell["post_id"].isin(post_ids)]
                        st.session_state["posts_sell"] = df_sell_new
                        _save_xlsx(df_sell_new, POSTS_SELL_XLSX)

                        # G·ª° pending_notifications
                        for pid in post_ids:
                            if pid in st.session_state["pending_notifications"]:
                                st.session_state["pending_notifications"].remove(pid)

                        st.success(f"ƒê√£ duy·ªát {len(post_ids)} tin b√°n.")

            with col2:
                if st.button("‚ùå T·ª´ ch·ªëi tin b√°n"):
                    if selected_sell.empty:
                        st.warning("Ch∆∞a ch·ªçn d√≤ng ƒë·ªÉ t·ª´ ch·ªëi.")
                    else:
                        post_ids = selected_sell["post_id"].tolist()

                        # L∆∞u rejected
                        rejected = _read_xlsx_if_exists(REJECTED_XLSX)
                        rejected = pd.concat(
                            [rejected, df_sell[df_sell["post_id"].isin(post_ids)]],
                            ignore_index=True
                        )
                        _save_xlsx(rejected, REJECTED_XLSX)

                        df_sell_new = df_sell[~df_sell["post_id"].isin(post_ids)]
                        st.session_state["posts_sell"] = df_sell_new
                        _save_xlsx(df_sell_new, POSTS_SELL_XLSX)

                        for pid in post_ids:
                            if pid in st.session_state["pending_notifications"]:
                                st.session_state["pending_notifications"].remove(pid)

                        st.success(f"ƒê√£ t·ª´ ch·ªëi {len(post_ids)} tin b√°n.")

    st.markdown("---")

    # ===========================
    #     X·ª¨ L√ù TIN ƒêƒÇNG MUA
    # ===========================
    if manage_buy:

        st.subheader("üõí Tin ƒëƒÉng mua (ch·ªù duy·ªát)")

        df_buy = st.session_state.get("posts_buy", pd.DataFrame()).copy()

        if df_buy.empty:
            st.info("Kh√¥ng c√≥ tin ƒëƒÉng mua n√†o.")
        else:
            df_buy_display = df_buy.copy()
            df_buy_display["selected"] = False

            df_buy_display = reorder_columns(df_buy_display)
            df_buy_display = rename_columns_vn(df_buy_display, mode="buy")

            edited_buy = st.data_editor(
                df_buy_display,
                use_container_width=True,
                hide_index=True,
                key="editor_buy"
            )

            selected_buy = edited_buy[edited_buy["Ch·ªçn"] == True]

            col3, col4 = st.columns(2)

            with col3:
                if st.button("‚úîÔ∏è Duy·ªát tin mua"):
                    if selected_buy.empty:
                        st.warning("Ch∆∞a ch·ªçn d√≤ng ƒë·ªÉ duy·ªát.")
                    else:
                        post_ids = selected_buy["post_id"].tolist()

                        approved = _read_xlsx_if_exists(APPROVED_BUY_XLSX)
                        approved = pd.concat(
                            [approved, df_buy[df_buy["post_id"].isin(post_ids)]],
                            ignore_index=True
                        )
                        _save_xlsx(approved, APPROVED_BUY_XLSX)

                        df_buy_new = df_buy[~df_buy["post_id"].isin(post_ids)]
                        st.session_state["posts_buy"] = df_buy_new
                        _save_xlsx(df_buy_new, POSTS_BUY_XLSX)

                        for pid in post_ids:
                            if pid in st.session_state["pending_notifications"]:
                                st.session_state["pending_notifications"].remove(pid)

                        st.success(f"ƒê√£ duy·ªát {len(post_ids)} tin mua.")

            with col4:
                if st.button("‚ùå T·ª´ ch·ªëi tin mua"):
                    if selected_buy.empty:
                        st.warning("Ch∆∞a ch·ªçn d√≤ng ƒë·ªÉ t·ª´ ch·ªëi.")
                    else:
                        post_ids = selected_buy["post_id"].tolist()

                        rejected = _read_xlsx_if_exists(REJECTED_XLSX)
                        rejected = pd.concat(
                            [rejected, df_buy[df_buy["post_id"].isin(post_ids)]],
                            ignore_index=True
                        )
                        _save_xlsx(rejected, REJECTED_XLSX)

                        df_buy_new = df_buy[~df_buy["post_id"].isin(post_ids)]
                        st.session_state["posts_buy"] = df_buy_new
                        _save_xlsx(df_buy_new, POSTS_BUY_XLSX)

                        for pid in post_ids:
                            if pid in st.session_state["pending_notifications"]:
                                st.session_state["pending_notifications"].remove(pid)

                        st.success(f"ƒê√£ t·ª´ ch·ªëi {len(post_ids)} tin mua.")

# ------------------ AUTHOR PAGE ------------------
elif choice == "Th√¥ng tin t√°c gi·∫£":
    st.header("üë§ Nh√≥m t√°c gi·∫£ d·ª± √°n")
    st.write("""
    **H·ªì Th·ªã Qu·ª≥nh Nh∆∞**  
    **Nguy·ªÖn VƒÉn C∆∞·ªùng**  
    **Nguy·ªÖn Th·ªã Tuy·∫øt Anh**  
    """)
